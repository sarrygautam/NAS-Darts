
import numpy as np
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications.xception import preprocess_input
from tensorflow.keras.preprocessing import image

# Load the pre-trained Xception model
model = Xception(weights='imagenet', include_top=False, pooling='avg')

# Load and preprocess your image
image_path = '/content/drive/MyDrive/DayLight/ChdVideo100101.png'
img = image.load_img(image_path, target_size=(299, 299))  # Xception requires input size (299, 299)
img = image.img_to_array(img)
img = np.expand_dims(img, axis=0)
img = preprocess_input(img)

# Extract features from the image
features = model.predict(img)
print("here are the feaures")
features


import torch
import torchvision.models as models
from torchvision import transforms
from PIL import Image
from torchvision.ops import nms
import matplotlib.pyplot as plt
import matplotlib.patches as patches

import random

COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',
    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]


# Load a pre-trained Faster R-CNN model
model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Function to transform the input image
def transform_image(image_path):
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    image = Image.open(image_path)
    image = transform(image).unsqueeze(0)
    return image


def extract_features(image_path):
    image = transform_image(image_path)
    with torch.no_grad():
        output = model(image)[0]
    # Convert label IDs to names
    output['labels'] = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in output['labels']]
    return output

# Example usage
#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Rain/rain_storm-002.jpg'  # Replace with your image path

#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Blooming/processed_110.jpg'  # Replace with your image path


#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Day/ChdVideo100521.png'  # Replace with your image path



#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Rain/rain106.jpg'  # Replace with your image path

#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Night/nightVideo400061.png'  # Replace with your image path


#image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Sand/Sand/dusttornado-012.jpg'  # Replace with your image path

'''

image_path = '/content/drive/MyDrive/Multi-class Weather Dataset/Snow/Snow/snow_storm-010.jpg'  # Replace with your image path

'''
features = extract_features(image_path)
print(features)


def visualize_image_with_features(image_path, features):
    # Load the image
    image = Image.open(image_path)

    # Create a matplotlib figure
    fig, ax = plt.subplots(1)
    ax.imshow(image)

    # Generate random colors
    colors = {}
    for label in set(features['labels']):
        colors[label] = (random.random(), random.random(), random.random())

    # Iterate over the detected objects
    for box, label in zip(features['boxes'], features['labels']):
        # Extract coordinates and dimensions of the bounding box
        x, y, x2, y2 = box
        w, h = x2 - x, y2 - y


         # Choose a color based on the label
        color = colors[label]


        # Create a rectangle patch and add it to the plot
        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')
        ax.add_patch(rect)

        # Add a label near the bounding box
        ax.text(x, y, label, fontsize=10, bbox=dict(facecolor=color, alpha=0.5))

    # Display the image with bounding boxes
    plt.show()


visualize_image_with_features(image_path, features)


def extract_features_with_nms(image_path, iou_threshold=0.3, score_threshold=0.5):
    image = transform_image(image_path)
    with torch.no_grad():
        predictions = model(image)[0]

    # Filter out predictions with low scores
    high_scores_idx = predictions['scores'] > score_threshold
    boxes = predictions['boxes'][high_scores_idx]
    labels = predictions['labels'][high_scores_idx]
    scores = predictions['scores'][high_scores_idx]

    # Apply Non-Maximum Suppression (NMS)
    nms_indices = nms(boxes, scores, iou_threshold)
    nms_boxes = boxes[nms_indices]
    nms_labels = labels[nms_indices]
    nms_scores = scores[nms_indices]

    # Convert label IDs to names
    nms_labels = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in nms_labels.tolist()]

    return {'boxes': nms_boxes, 'labels': nms_labels, 'scores': nms_scores}


features_with_nms = extract_features_with_nms(image_path)
visualize_image_with_features(image_path, features_with_nms)



import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.colors as mcolors
import numpy as np

def visualize_image_with_colored_scores(image_path, features):
    # Load the image
    image = Image.open(image_path)

    # Create a matplotlib figure
    fig, ax = plt.subplots(1)
    ax.imshow(image)

    # Normalize the scores to map them to a colormap
    scores = features['scores']
    norm = plt.Normalize(scores.min(), scores.max())
    cmap = plt.cm.get_cmap('coolwarm')

    # Iterate over the detected objects
    for box, label, score in zip(features['boxes'], features['labels'], scores):
        # Extract coordinates and dimensions of the bounding box
        x, y, x2, y2 = box
        w, h = x2 - x, y2 - y

        # Choose a color based on the score
        color = cmap(norm(score))

        # Create a rectangle patch and add it to the plot
        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')
        ax.add_patch(rect)

        # Add a label near the bounding box
        ax.text(x, y, f'{label}: {score:.2f}', fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))

    # Display the image with bounding boxes
    plt.show()

features_with_nms = extract_features_with_nms(image_path)

# Print the number of detected objects
num_detected_objects = len(features_with_nms['labels'])
print(f"Faster R-CNN detected {num_detected_objects} objects in the image.")#

visualize_image_with_colored_scores(image_path, features_with_nms)





import matplotlib.pyplot as plt

def plot_confidence_scores(features):
    scores = features['scores']
    labels = features['labels']

    # Generate unique colors for each detected object
    unique_labels = set(labels)
    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))
    label_color_map = dict(zip(unique_labels, colors))

    # Create a line plot
    plt.figure(figsize=(10, 6))
    for label, score in zip(labels, scores):
        plt.plot([0, 1], [score, score], label=label, color=label_color_map[label], linewidth=2)

    # Customize the plot
    plt.xlabel('Objects')
    plt.ylabel('Confidence Score')
    plt.title('Confidence Scores of Detected Objects')
    plt.legend(loc='best')

    # Show the plot
    plt.show()

# Call the function with the features extracted by Faster R-CNN
features_with_nms = extract_features_with_nms(image_path)
plot_confidence_scores(features_with_nms)



import matplotlib.pyplot as plt
import numpy as np

def plot_confidence_scores_bar_chart(features):
    scores = features['scores']
    labels = features['labels']

    # Map each label to an integer for plotting
    unique_labels = list(set(labels))
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    label_positions = [label_to_int[label] for label in labels]

    # Generate unique colors for each label
    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))

    # Create a bar chart
    plt.figure(figsize=(2, 2))
    bars = plt.bar(label_positions, scores, color=colors)

    # Customize the plot
    plt.xlabel('Objects')
    plt.ylabel('Confidence Score')
    plt.title('Confidence Scores of Detected Objects')
    plt.xticks(ticks=np.arange(len(unique_labels)), labels=unique_labels, rotation=45)

    # Adding a legend (optional, might be cluttered if too many objects)
    # plt.legend(bars, unique_labels)

    # Show the plot
    plt.show()

# Call the function with the features extracted by Faster R-CNN
features_with_nms = extract_features_with_nms(image_path)
plot_confidence_scores_bar_chart(features_with_nms)







import matplotlib.pyplot as plt
import numpy as np
import matplotlib.colors as mcolors

def plot_confidence_scores_heatmap(features):
    scores = features['scores']
    labels = features['labels']

    # Map each label to an integer for plotting
    unique_labels = list(set(labels))
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    label_positions = [label_to_int[label] for label in labels]

    # Normalize the scores to map them to a colormap
    norm = plt.Normalize(scores.min(), scores.max())
    cmap = plt.cm.get_cmap('cool')

    # Create a bar chart
    plt.figure(figsize=(2, 3))
    bars = plt.bar(label_positions, scores, color=cmap(norm(scores)))

    # Customize the plot
    plt.xlabel('Objects')
    plt.ylabel('Confidence Score')
    plt.title('Confidence Scores Bar Chart of Detected Objects in Rainy Weather')
    plt.xticks(ticks=np.arange(len(unique_labels)), labels=unique_labels, rotation=45)
    plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=plt.gca(), label='Confidence Score')

    # Show the plot
    plt.show()

# Call the function with the features extracted by Faster R-CNN
features_with_nms = extract_features_with_nms(image_path)
plot_confidence_scores_heatmap(features_with_nms)

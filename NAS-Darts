
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import torchvision.datasets as datasets

input_shape = (32, 32)
# Define your custom dataset class by inheriting from the Dataset class
class CustomDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data = datasets.ImageFolder(root=data_dir, transform=transform)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image, label = self.data[idx]
        return image, label

data_dir = '/content/drive/MyDrive/Traffic Light Detection Dataset'  # Replace with the actual data directory
custom_dataset = CustomDataset(data_dir=data_dir, transform=transforms)

# Define batch size and create a data loader
batch_size = 32
data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=4)

# Define the operations and cell classes
class Zero(nn.Module):
    def __init__(self, stride):
        super(Zero, self).__init__()
        self.stride = stride

    def forward(self, x):
        if self.stride == 1:
            return x * 0.0
        else:
            return x[:, :, ::self.stride, ::self.stride] * 0.0

class Identity(nn.Module):
    def __init__(self):
        super(Identity, self).__init__()

    def forward(self, x):
        return x

class DilConv(nn.Module):
    def __init__(self, C_in, C_out, kernel_size, stride, dilation, padding, affine=True):
        super(DilConv, self).__init__()
        self.op = nn.Sequential(
            nn.Conv2d(C_in, C_in, kernel_size=1, stride=stride, padding=padding, dilation=dilation, groups=C_in, bias=False),
            nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),
            nn.BatchNorm2d(C_out, affine=affine)
        )

    def forward(self, x):
        return self.op(x)

class SepConv(nn.Module):
    def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):
        super(SepConv, self).__init__()
        self.op = nn.Sequential(
            nn.Conv2d(C_in, C_in, kernel_size=1, stride=stride, padding=padding, groups=C_in, bias=False),
            nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),
            nn.BatchNorm2d(C_out, affine=affine)
        )

    def forward(self, x):
        return self.op(x)

class FactorizedReduce(nn.Module):
    def __init__(self, C_in, C_out, affine=True):
        super(FactorizedReduce, self).__init__()
        self.relu = nn.ReLU()
        self.conv_1 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)
        self.conv_2 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)
        self.bn = nn.BatchNorm2d(C_out, affine=affine)

    def forward(self, x):
        x = self.relu(x)
        path1 = self.conv_1(x)
        path2 = self.conv_2(x[:, :, 1:, 1:])
        out = torch.cat([path1, path2], dim=1)
        out = self.bn(out)
        return out

class ReLUConvBN(nn.Module):
    def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):
        super(ReLUConvBN, self).__init__()
        self.op = nn.Sequential(
            nn.ReLU(inplace=False),
            nn.Conv2d(C_in, C_out, kernel_size=2, stride=stride, padding=padding, bias=False),
            nn.BatchNorm2d(C_out, affine=affine)
        )

    def forward(self, x):
        return self.op(x)

# Define a training function
def train(train_loader, model, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        for batch_idx, (input, target) in enumerate(train_loader):
            input, target = input.cuda(), target.cuda()
            input, target = Variable(input), Variable(target)
            optimizer.zero_grad()
            logits = model(input)
            loss = criterion(logits, target)
            loss.backward()
            optimizer.step()

# Define the operations (OPS) dictionary
OPS = {
    'none': lambda C, stride, affine: Zero(stride),
    'avg_pool_3x3': lambda C, stride, affine: nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False),
    'max_pool_3x3': lambda C, stride, affine: nn.MaxPool2d(3, stride=stride, padding=1),
    'skip_connect': lambda C, stride, affine: Identity(),
    'sep_conv_3x3': lambda C, stride, affine: SepConv(C, C, 3, stride, 1, affine=affine),
    'sep_conv_5x5': lambda C, stride, affine: SepConv(C, C, 5, stride, 2, affine=affine),
    'dil_conv_3x3': lambda C, stride, affine: DilConv(C, C, 3, stride, 2, 2, affine=affine),
    'dil_conv_5x5': lambda C, stride, affine: DilConv(C, C, 5, stride, 4, 2, affine=affine),
    'factorized_reduce': lambda C, stride, affine: FactorizedReduce(C, C, affine=affine),
}

# Define the DARTS architecture
class Darts(nn.Module):
    def __init__(self, C, num_classes, layers, criterion):
        super(Darts, self).__init__()
        self.C = C
        self.num_classes = num_classes
        self.layers = layers
        self.criterion = criterion
        self._initialize_alphas()

        # Create stem
        self.stem0 = nn.Sequential(
            nn.Conv2d(3, C // 3, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(C // 3)
        )

        # Create cells
        self.cells = nn.ModuleList()
        reduction_prev = False
        C_prev_prev, C_prev, C_curr = C // 3, C // 3, C // 3 * 2
        for i in range(layers):
            if i in [layers // 3, 2 * layers // 3]:
                C_curr *= 2
                reduction =True
            else:
                reduction = False
            cell = Cell(C_prev_prev, C_prev, C_curr, reduction, reduction_prev)
            reduction_prev = reduction
            self.cells += [cell]
            C_prev_prev, C_prev = C_prev, C_curr

        # Create classifier head
        self.global_pooling = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Linear(C_prev, num_classes)

    def forward(self, input):
        s0 = s1 = self.stem0(input)
        for i, cell in enumerate(self.cells):
          s0, s1 = s1, cell(s0, s1, self.alphas[i])
          out = self.global_pooling(s1)
          logits = self.classifier(out.view(out.size(0), -1))
        return logits

    def _initialize_alphas(self):
        num_ops = len(OPS)
        self.alphas = nn.ParameterList()
        for i in range(self.layers):
            self.alphas.append(nn.Parameter(1e-3 * torch.randn(num_ops, 2)))

stride =2

class Cell(nn.Module):
    def __init__(self, C_prev_prev, C_prev, C_curr, reduction, reduction_prev):
        super(Cell, self).__init__()
        if reduction_prev:
            self.preprocess0 = FactorizedReduce(C_prev_prev, C_curr, affine=False)
        else:
            self.preprocess0 = ReLUConvBN(C_prev_prev, C_curr, 1, 1, 0, affine=False)
        self.preprocess1 = ReLUConvBN(C_prev, C_curr, 1, 1, 0, affine=False)

        self.ops = nn.ModuleList()
        self.multiplier = len(OPS)
        for primitive in ['none', 'avg_pool_3x3', 'max_pool_3x3', 'skip_connect', 'sep_conv_3x3', 'sep_conv_5x5', 'dil_conv_3x3', 'dil_conv_5x5']:
            op = OPS[primitive](C_curr, stride, False)
            if 'pool' in primitive:
                op = nn.Sequential(op, nn.BatchNorm2d(C_curr, affine=False))
            self.ops.append(op)

    def forward(self, x0, x1, weights):
        x0 = self.preprocess0(x0)
        x1 = self.preprocess1(x1)
        states = [x0, x1]
        offset = 0
        outputs = []

        for i in range(len(self.ops)):
            op = self.ops[i]

            # Check if the operation is not None or Identity
            if not isinstance(op, (Zero, Identity)):
                # Check if the kernel size is greater than the input size
                if isinstance(op, nn.MaxPool2d) and op.kernel_size > states[-1].size(2):
                    # Reduce the kernel size to the input size
                    op = nn.MaxPool2d(states[-1].size(2), stride=op.stride, padding=0)

                s = op(states[-1], weights[offset:offset+len(op)], False)
                offset += len(op)
            else:
                # Skip Zero and Identity operations
                s = states[-1]

            states.append(s)
            outputs.append(s)

        # Ensure that tensors have the same size except for dimension 1
        for i in range(1, len(outputs)):
            if outputs[i].size(1) != outputs[0].size(1):
                diff = outputs[0].size(1) - outputs[i].size(1)
                if diff > 0:
                    # Pad tensors with zeros along dimension 1
                    outputs[i] = F.pad(outputs[i], (0, 0, 0, 0, 0, diff))
                else:
                    # Crop tensors along dimension 1
                    outputs[i] = outputs[i][:, :, :, :outputs[0].size(3)]

        # Concatenate tensors along dimension 1
        concatenated_output = torch.cat(outputs[-self.multiplier:], dim=1)

        return concatenated_output


# Define a simple cell structure
class MixedOp(nn.Module):
    def __init__(self, C, stride):
        super(MixedOp, self).__init__()
        self.ops = nn.ModuleList()
        for primitive in ['none', 'avg_pool_3x3', 'max_pool_3x3', 'skip_connect', 'sep_conv_3x3', 'sep_conv_5x5', 'dil_conv_3x3', 'dil_conv_5x5']:
            op = OPS[primitive](C, stride, False)
            if 'pool' in primitive:
                op = nn.Sequential(op, nn.BatchNorm2d(C, affine=False))
            self.ops.append(op)

    def forward(self, x, weights):
        return sum(w * op(x) for w, op in zip(weights, self.ops))

# Main training and testing function
def train_and_test(data_dir, batch_size, num_epochs, C, layers, lr, momentum, weight_decay):
    # Define your data transformations and prepare your custom dataset
    transform = transforms.Compose([transforms.Resize(input_shape),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    train_dataset = CustomDataset(data_dir=data_dir, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)

    # Define your model, criterion, and optimizer
    model = Darts(C=C, num_classes=10, layers=layers, criterion=nn.CrossEntropyLoss()).cuda()
    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)
    criterion = nn.CrossEntropyLoss()


    # Training loop
    #train(train_loader, model, criterion, optimizer, num_epochs)


    for epoch in range(num_epochs):
        for batch_idx, (input, target) in enumerate(train_loader):
            input, target = input.cuda(), target.cuda()
            input, target = Variable(input), Variable(target)
            optimizer.zero_grad()
            logits = model(input)
            loss = criterion(logits, target)
            loss.backward()
            optimizer.step()


            true_labels.extend(target.cpu().numpy())
            pred_labels.extend(predicted.cpu().numpy())

        # Calculate precision, recall, and F1-score
        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')
        print(f'Epoch: {epoch+1}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')


if __name__ == '__main__':
    data_dir = '/content/drive/MyDrive/Traffic Light Detection Dataset'
    batch_size = 32
    num_epochs = 20
    C = 36
    layers = 20
    lr = 0.025
    momentum = 0.9
    weight_decay = 3e-4

    train_and_test(data_dir, batch_size, num_epochs, C, layers, lr, momentum, weight_decay)
